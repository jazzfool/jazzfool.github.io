[{"categories":null,"contents":"This guide was written for Godot 4.0 (Alpha 1 at the time of writing), but does not use any 4.0-specific features\nOutlines are a handy visual tool in games to show focus on objects. Unfortunately for Godot, I haven\u0026rsquo;t seen much content on how to make nice looking outlines for 3D objects.\nThis guide will show you how to make outlines that look like this:\n   Step 1: Isolating depth  Firstly, we need to isolate the depth for the objects we want to outline. To do this, we need to get our hands dirty with SubViewport (Viewport pre-4.0).\nThis is the scene tree you need to set up:\n(Note: OutlineViewport and GameViewport are of type SubViewport, and GameViewportContainer is of type SubViewportContainer)\nThe Node3D under GameViewport is where your entire game scene will go. Objects that we want to outline will be duplicated under OutlineViewport/Node3D as siblings of Camera3D. Finally, the script attached to Node2D will be managing everything.\nViewports do not have a built-in way to render depth-only, so the only way to do this currently is to put a depth-visualising material on all the objects in OutlineViewport.\nHere is the shader code for that material:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // depth_only.gdshader shader_type spatial; render_mode unshaded, skip_vertex_transform; varying float depth; void vertex() { VERTEX = (MODELVIEW_MATRIX * vec4(VERTEX, 1.0)).xyz; NORMAL = (MODELVIEW_MATRIX * vec4(VERTEX, 0.0)).xyz; vec4 ndc = PROJECTION_MATRIX * vec4(VERTEX, 1.0); ndc.xyz /= ndc.w; depth = ndc.z; } void fragment() { ALBEDO = vec3(depth); }   Here is the script we\u0026rsquo;ll attach to objects inside OutlineViewport:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # OutlineCopy.gd class_name OutlineCopy extends MeshInstance3D var original: Node3D = null; const depth_only = preload(\u0026#34;res://depth_only.gdshader\u0026#34;) func _ready(): var material := ShaderMaterial.new() material.shader = depth_only material_override = material func _process(delta): if is_instance_valid(original): global_transform = original.global_transform   The above will only replicate the global transform, but you may want to replicate other properties, for example the mesh if it changes at runtime.\nFinally, this is the script we\u0026rsquo;ll attach to the root Node2D:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  # Root.gd extends Node2D @onready var game_viewport_container: SubViewportContainer = $GameViewportContainer @onready var game_viewport: SubViewport = $GameViewportContainer/GameViewport @onready var game_camera: Camera3D = $GameViewportContainer/GameViewport/Node3D/Camera3D @onready var outline_viewport: SubViewport = $OutlineViewport @onready var outline_camera: Camera3D = $OutlineViewport/Node3D/Camera3D @onready var outline_scene: Node3D = $OutlineViewport/Node3D const OutlineCopy := preload(\u0026#34;res://OutlineCopy.gd\u0026#34;) func _ready(): game_viewport_container.material.set_shader_param(\u0026#34;outline_viewport_texture\u0026#34;, outline_viewport.get_texture()) # call add_outline on the objects you want here, or anywhere really func _process(delta): # synchronise viewport size, camera transform, and camera FOV var viewport := get_viewport() if game_viewport.size != viewport.size: game_viewport.size = viewport.size if outline_viewport.size != game_viewport.size: outline_viewport.size = game_viewport.size outline_camera.fov = game_camera.fov outline_camera.global_transform = game_camera.global_transform func add_outline(node: MeshInstance3D): if is_instance_valid(node.get_meta(\u0026#34;outline_object\u0026#34;)): # object already has an outline return # 0 disables all duplicate flags - we only want to duplicate the visuals var copy = node.duplicate(0) copy.set_script(OutlineCopy) copy.original = node outline_scene.add_child(copy) node.set_meta(\u0026#34;outline_object\u0026#34;, copy) func remove_outline(node: MeshInstance3D): var outline: MeshInstance3D = node.get_meta(\u0026#34;outline_object\u0026#34;) if is_instance_valid(outline): outline.queue_free()   You don\u0026rsquo;t have to add objects to OutlineViewport through code as it can also be done manually, but just make sure the material is depth_only.gdshader and the script attached is OutlineCopy.gd.\nWe should now have a viewport that renders the depth buffer only for objects that we tell it to.\n   Step 2: Outline  Now that we have a depth buffer isolated to objects that are outlined, we can just apply a post-process outline. We run dead-simple edge detection on said depth buffer, compare, and if the \u0026ldquo;edge value\u0026rdquo; falls above some threshold then we output a fixed color instead of the scene color.\nJust add a shader material to GameViewportContainer with the following shader:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // post_outline.gdshader shader_type canvas_item; uniform sampler2D outline_viewport_texture; uniform vec4 outline_color : hint_color = vec4(1, 0, 0, 1); uniform float outline_thickness = 2.0; float tex(vec2 uv, vec2 ts, float x, float y) { return texture(outline_viewport_texture, uv + vec2(x, y) * ts).r; } float outline(vec2 uv, float thickness) { vec2 ts = thickness / vec2(textureSize(outline_viewport_texture, 0)); // only 4 texture samples! return (abs(tex(uv, ts, -1, -1) - tex(uv, ts, 1, 1)) + abs(tex(uv, ts, 1, -1) - tex(uv, ts, -1, 1))); } void fragment() { vec3 color = texture(TEXTURE, UV).xyz; float outline = outline(UV, outline_thickness); COLOR = mix(vec4(color, 1), outline_color, float(outline \u0026gt; 0.05)); }   Credit for this shader goes to http://blog.dalton.gd/quick-outline-ue4/ .\nThat\u0026rsquo;s it!\n   Shortcomings   Wasteful on memory. Since SubViewport does not have a depth-only render mode (ideally this would be in the form of a depth buffer Debug Draw mode - I may open a PR for this in the future), there are basically two depth buffers, one of them in the format R8G8B8A8 (which is even more wasteful for a depth target!). Wasteful on GPU usage. GPUs have hardware depth testing and writing. We should be just utilising that in order to render our custom depth buffer and in fact it is, but only in a depth attachment we can\u0026rsquo;t access, so we need to make our own depth-writing shader for no good reason. Again, this is just Godot\u0026rsquo;s fault for not exposing the depth buffer of a viewport. Large thickness values don\u0026rsquo;t look great. This is because the edge detection only looks at the 4 adjacent texels to determine an outline and simply just scales the UV outwards to simulate thickness. \u0026ldquo;Real\u0026rdquo; thickness-based edge detection would need to look at pi * thickness * thickness texels.  ","date":"Feb 09","permalink":"/post/godot-outlines/","tags":null,"title":"3D Outlines in Godot"},{"categories":null,"contents":"   Past  Many are familiar with the practicality of the Qt API. It abides by what most already know of object-oriented programming and manually mutated states. By far the biggest advantage of such an API is its clarity; there is nothing to learn or understand as what you write is exactly what you mean.\n1 2 3 4 5 6 7 8 9 10 11 12 13  int state = 5; // ...  QPushButton* add = new QPushButton(this); add-\u0026gt;setLayout(top); display-\u0026gt;setValue(state); connect(add, \u0026amp;QPushButton::pressed, [\u0026amp;]() { state += this-\u0026gt;spinBox-\u0026gt;value(); display-\u0026gt;setValue(state); });   Already we see a flaw however. We are duplicating procedures. display-\u0026gt;setValue must be called twice in order to have the UI behave as we want.\nThis problem is really the consequence of two concerns in GUI APIs:\n Initialization/update phases Lack of a single source of truth  The former issue is less of a concern, however the latter is strikingly critical. There is some widget display that depends on our data and as a result we must propagate any mutations to that data. What we have done - and you may not have realized it - is write an implied dependency between state and some data inside display. In fact, we do this kind of thing all the time without realizing it.\nUnfortunately, this implied dependency is brittle. It can easily be shattered by any third party that inconsistently mutates state/display, being completely unaware of the unspoken link (i.e., implied dependency) between state and display that we wrote here.\nWhose fault would that be? I argue it\u0026rsquo;s the API\u0026rsquo;s fault.\n   Present  Thankfully, we already figured this one out; let\u0026rsquo;s keep the dependencies implicit but instead lock it down under a declarative interface.\nA prime, and maybe familiar example, is React.\n1 2 3 4 5 6 7 8 9 10 11  function Stateful() { const [state, setState] = useState(5); const [spinBox, setSpinBox] = useState(0); return ( // ... \t\u0026lt;button onClick={() =\u0026gt; setState(state + spinBox)}\u0026gt; \u0026lt;Display value={state}\u0026gt; // ... \t); }   The UI system still has no clue that display and state are linked, yet our code (and in particular our button callback) is more concise. No initialization phase needed!\nSo how is black magic like this possible? Simple; it\u0026rsquo;s all phony. Of course there is no underlying update procedure being generated, how could there be one if React doesn\u0026rsquo;t even know the state dependencies! No, instead React simply forgets about trying to keep track of all that and just recreates our UI tree every time something happens, then generates stable identities to remember the previous frame\u0026rsquo;s state (which is all wrapped up and abstracted away into a single useState).\nFairly inefficient at runtime, yet UIs are far more expressive with React. As a side bonus, the UI tree is declarative and thus shifting around the UI structure dynamically is a breeze compared to something like Qt.\nI also include Dear ImGui and its kin in this category. If anything, Dear ImGui is even more dynamic than React since it doesn\u0026rsquo;t even bother to do any diffing.\n   Explicit dependencies  Now we venture out into the unknown in an attempt to scope out possible solutions. We\u0026rsquo;ve seen two examples of the opposite extremas of GUI APIs:\n Qt with its highly imperative and object-oriented procedures, proving to be conservative and practical React with an expressive and declarative interface at the cost of performance  It\u0026rsquo;s fair to say then that the ideal solution is a declarative interface, like React, that is performant, like Qt. The key to such a GUI API is something neither Qt, React, or any other GUI library like them have: Explicit dependencies.\nMore specifically, an explicit dependency graph - in other words, a directed acyclic graph between all state.\nAll the GUIs we write will always have a dependency graph, hiding in plain sight, but they are never written out. You never write down that two states depend on each other. You only describe the relationship through mutating procedures such as callbacks. Although to be fair, you probably don\u0026rsquo;t want to write out those dependencies by hand either - and you don\u0026rsquo;t have to.\nThe idea is simple: GUIs should be a metaprogram which encode dependencies and mutations, after which the UI system steps in, builds an explicit dependency graph, and writes the actual GUI program with all the dependencies resolved back down to an implied form.\nIn fact, Svelte already does exactly this using a precompiler.\nHere\u0026rsquo;s a rough sketch of exactly what I mean. Let\u0026rsquo;s start with the \u0026ldquo;metaprogram\u0026rdquo; of the UI. This will just be our React code (yup, the UI metaprogram is identical to regular UI code).\n1 2 3 4 5 6 7 8 9 10 11  function Stateful() { const [state, setState] = useState(5); const [spinBox, setSpinBox] = useState(0); return ( // ... \t\u0026lt;button onClick={() =\u0026gt; setState(state + spinBox)}\u0026gt; \u0026lt;Display value={state}\u0026gt; // ... \t); }   To really understand what I mean by \u0026ldquo;UI metaprogram\u0026rdquo;, let\u0026rsquo;s look at it from a different perspective. Instead of seeing the returned UI tree as something to be recreated every frame, you should view it as a static template, waiting to be filled with real data. Instead of seeing useState as a call to grab the cached state, see it as a node in the dependency graph. Finally, consider the properties (e.g., value={state}) to be a directed edge from state to value.\nThat\u0026rsquo;s it. That\u0026rsquo;s all the UI system would need to generate retained-mode UI code. Let me rewrite it in a more step-by-step sense:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  function Stateful(graph) { var w = graph.addWidget(); graph.addNode(w, \u0026#34;state\u0026#34;, 5); graph.addNode(w, \u0026#34;spinBox\u0026#34;, 0); var btn = button(graph); var display = Display(graph); graph.addReaction(btn, \u0026#34;onClick\u0026#34;, graph.mutate(w, \u0026#34;state\u0026#34;, (state, graph) =\u0026gt; state + graph.get(w, \u0026#34;spinBox\u0026#34;))); graph.addDependency(display, \u0026#34;value\u0026#34;, w, \u0026#34;state\u0026#34;); return w; }   For example, if this graph was an interface to a UI precompiler like Svelte, then it may output the following.\n1 2 3 4 5 6 7 8 9 10  var state = 5; // given by graph.addNode var spinBox = 0; // given by graph.addNode  var btn = new Button(); var display = new Display(); btn.onClick = () =\u0026gt; { // given by graph.addReaction \tstate = state + spinBox; // given by graph.mutate \tdisplay.value = state; // given by graph.addDependency };   The real challenge comes from doing this without a precompiler.\n   Black box  One way of finding mutating code paths from declarative code is by running \u0026ldquo;tracers\u0026rdquo; through the function. If it were a black box (which it effectively is), then it can be reverse engineered by tweaking inputs and observing outputs.\nSay there is a mysterious function, mystery, which takes application state and produces a UI tree. To make this easier, assume we\u0026rsquo;re given two additional helper functions; state_muts (which produces all the possible mutations of the state), and find_mutation (which diffs the UI tree to find and encode the exact UI tree mutations that occurred).\n1 2 3 4 5 6 7 8 9  letmutstate=State::default();letmutui=mystery(\u0026amp;state);letmutlut=HashMap::\u0026lt;StateMutation,UiMutation\u0026gt;::new();forstate_mutinstate_muts(){state_mut.patch(state);letnew_ui=mystery(state);lut.insert(state_mut,find_mutation(\u0026amp;ui,\u0026amp;new_ui));ui=new_ui;}  By doing this, we have built a look-up table, lut, which maps state mutations to UI mutations. Having this LUT means that whenever the state does change, we don\u0026rsquo;t need to run the entire process again since we can simply consult this LUT to find how we should change the UI correspondingly. This is something of a differential of mystery; small changes to the input to observe the small change to the output.\nUnfortunately this notion only works in the abstract sense. It would be quite elegant if this was indeed reduced to a calculus problem, but such UI mutations are veiled behind string labels and other widget properties. To make this work, it would require a property system - something to direly avoid (at least on a library-level).\n   Maps  Many parts of a UI fall down to a simple mapping, State -\u0026gt; UI, Number -\u0026gt; Formatted String, Formatted String -\u0026gt; Label, etc. We can leverage this and formalize the notion that state is derived off of other state.\n1 2 3  letcount=State::new(0);letformatted_string=count.map(|count|format!(\u0026#34;Count: {}\u0026#34;,count));label.set_label(formatted_string);  This enables us to write the UI in whatever manner we desire (imperative or declarative), yet it will be able to update itself without any additional reactivity by us. This solution still poses some problems:\n State mappings must persistently hold a reference to the state they map. State mappings should be lazily evaluated (otherwise we\u0026rsquo;re back to square one in terms of performance).  The first problem can be solved with Rc\u0026lt;Cell\u0026lt;T\u0026gt;\u0026gt;, and as much as I despise the use of interior mutability in favour of letting data flow in the correct direction, state mappings are a graph and graphs have no single linear order.\nThe second problem is solved by using a semaphore-like system where each state holds the number of mutations, and so does each mapping. Whenever those numbers fall out of sync then the mapping must be re-evaluated.\nTake note of what we\u0026rsquo;ve done here. Dependencies are now crystal clear. By just looking at the code you can be certain that e.g., the label text is entirely dependent on count, because of the count.map(...).\nHere\u0026rsquo;s a proof-of-concept implementation in Rust.\n   Getting wild with async  Stepping away from the matter of dependencies for a second, letâ€™s explore a more novel approach to reactive UI as a whole.\nThis one is quite exotic and I haven\u0026rsquo;t seen it done before. The core idea is to have each widget be an async task which polls its in-going message channel and can spawn sub-tasks to act as child widgets. This implies that every widget essentially has its own event loop, rather than a single application-wide event loop for all widgets.\nA possible interface could like this.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  asyncfn my_widget(rcv: Receiver,out: Rc\u0026lt;Sender\u0026gt;){letmutcount=0;whileletSome(event)=rcv.next().await{matchevent{Event::Update(my_props)=\u0026gt;/* update props */,Event::Msg(my_msg)=\u0026gt;matchmy_msg{Msg::Incr=\u0026gt;{count+=1;out.render();},Msg::Decr=\u0026gt;{count-=1;out.render();},},Event::Render(to)=\u0026gt;{to.send(||{WidgetTask::new(column,((label,\u0026#34;Increment\u0026#34;),(button,||out.send_msg(Msg::Incr)),// out sends to rcv (button,||out.send_msg(Msg::Decr)),))});}}}}  Under the hood it would presumably use diffing, yet the diffing can be much more targeted as you can signal directly into a widget task to tell it to update itself. You can also set up a feedback loop to let yourself know of an external event. Moreover, using channels means you can set up any communication pipeline you want between any two widgets. I haven\u0026rsquo;t explored the limits of this kind of messaging and eventing system yet.\nOn the other hand, the interface above is verbose and ugly so it\u0026rsquo;s a much better idea to abstract the core message loop away and expose programmable parts of it with an interface.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  enum Msg{Incr,Decr,}struct Counter{count: i32,}#[async_trait]implWidgetforCounter{// Properties are the public interface of the widget (in place of setters). type Props=();type Message=Msg;// Called on spawn asyncfn new(_: Self::Props)-\u0026gt; Self{Counter{count: 0,}}// Called on diff asyncfn reduce(\u0026amp;mutself,_: Self::Props){}asyncfn update(\u0026amp;mutself,msg: \u0026amp;Msg){matchmsg{Msg::Incr=\u0026gt;self.count+=1,Msg::Decr=\u0026gt;self.count-=1,}}// This is only called after Self::update. // Since this only returns a tree of properties, the widget driver can either: // 1) Spawn the tasks if this is the first render. // 2) Diff and call `reduce` on the existing tree. asyncfn view(\u0026amp;self,out: MessageOut\u0026lt;Msg\u0026gt;)-\u0026gt; Column{// These functions return (Self::Props, Self::spawn) Column::with_children([Label::with_text(format!(\u0026#34;Count: {}\u0026#34;,self.count)),Row::with_children([Button::with_child(Label::with_text(\u0026#34;Increment\u0026#34;)).on_click(|_|out.send(Msg::Incr)),// Eventually invokes Self::update Button::with_child(Label::with_text(\u0026#34;Decrement\u0026#34;)).on_click(|_|out.send(Msg::Decr)),]),])}}  It shows strong resemblance to the Elm architecture, however in this example Msg can be piped directly into the widget\u0026rsquo;s message loop rather than cascading the messages down the view hierarchy. Therefore, the exact widget branch that was updated can be identified and diffed instead of blindly diffing the entire UI tree.\nSome things to investigate:\n Event order Layout and rendering Performance     Compromising  I think that reactive UI is quite elegant. It welcomes curious-minded exploration, functional purity, and theoretical analysis. However, I think that it appears so elegant that some are blinded by its applicability. Reactive declarative UI code looks beautiful when writing a counter, but what about a more \u0026ldquo;ugly\u0026rdquo; application? Something much more heavy-duty? Say, a video editor, or DAW, or drawing software. How will you map any \u0026ldquo;pure\u0026rdquo; data down?\nThe problem here is that the core of these kinds of applications is actually incredibly unrelated to the UI. A DAW\u0026rsquo;s core is just a DSP. A video editor\u0026rsquo;s core is mostly just a compositor. Blender\u0026rsquo;s mesh editor core comes down to a 3D scene stored in a few vertex buffers. Obviously a DAW isn\u0026rsquo;t just an interface to a DSP, it\u0026rsquo;s a big shell to add VSTs, MIDI, drums, etc. A video editor isn\u0026rsquo;t just an interface to a compositor, it\u0026rsquo;s a way to blend VFX, 3D scenes, and A/V. Then most obviously, Blender mesh editor isn\u0026rsquo;t just an interface to upload bytes to a vertex/index buffer.\nAll the value of these kinds of applications comes down to the UI and as such there\u0026rsquo;s practically no way to bridge the gap between the core and the UI without introducing a thick intermediate layer that has state only for the sake of the UI. That is something that reactive UI does not appreciate.\nReactive UI works extremely well where there\u0026rsquo;s a clear and direct connection between the UI and state. For example, a counter state maps directly to an incrementing button and a formatted label. However, a list of audio tracks does not quite map to a DAW.\nThere\u0026rsquo;s a time and place for reactive and declarative UI, and there\u0026rsquo;s a time and place for procedural and imperative UI. I advocate for a UI platform that allows you to mix the two seamlessly such that one can use imperative UI for the nitty-gritty widgets and declarative UI for the composition of widgets inside forms/panels. In fact, this idea is not so alien. Iced, for example, does exactly this, wherein the elementary building blocks of the declarative UI are irreducible widgets.\n   Closing thoughts  There is lots of room for playing around when it comes to reactive UI. In particular, I\u0026rsquo;m a fan of Raph Linus\u0026rsquo;s blog where he has made several posts exploring this very topic. I hope to see more work and movement occur in this space as it may very well shape the future of GUI libraries.\n","date":"Aug 01","permalink":"/post/reactive/","tags":null,"title":"Exploring reactive UI"},{"categories":null,"contents":"I\u0026rsquo;d like to think I\u0026rsquo;ve spent long enough in desktop GUI development. I\u0026rsquo;m disappointed by what I\u0026rsquo;ve seen as I\u0026rsquo;ve worked with a vast palette of desktop GUI solutions. Everything from Qt to Electron have their own hideous limbs with their very own creative ways burden you as you develop your app. That isn\u0026rsquo;t to discredit them all, as a few actually offer wonderful developer experiences (though often still lacking in practicality and applicability).\n   Electron  Electron is perhaps the most poor desktop GUI solution to pop up and it seems to have bred rapid adoption of browser technology into every corner of computing. The main problem with dragging along an entire browser isn\u0026rsquo;t that it\u0026rsquo;s bloated or memory-consuming (albeit those are still problems). It\u0026rsquo;s that they include a plethora of hidden mechanisms that will never benefit a fully controlled web-based environment (i.e., your app\u0026rsquo;s webpages). Think of the thousands of security patches and workarounds, the intricate DOM optimizations, the multi-webpage inter-process resource sharing. None of that will benefit an Electron app and will only slow it down. An Electron app will only display 3-4 webpages, all of which are fully controlled by the developer. Browsers, on the other hand, are designed to handle incredibly rare edge cases and exploits in the wildest parts of the internet.\nTo put it shortly, you\u0026rsquo;re misusing the software. It\u0026rsquo;s astonishing how some people continue to defend the use of Electron for its \u0026ldquo;developer productivity\u0026rdquo;. There is a hint of truth in that, but not in the way they think. Their defence is greatly misplaced. It\u0026rsquo;s not that Electron or Chromium itself gives any developer productivity; it\u0026rsquo;s the web ecosystem and front-end frameworks.\nFor all that I bash Electron, I believe it has taught a couple important lessons:\n There\u0026rsquo;s a huge appetite for a declarative desktop GUI library. Developers want support from an ecosystem, especially for a GUI.     Qt  Qt is a passable desktop GUI solution, but it still has its problems.\nFirstly, your application lives inside Qt, instead of the other way around. Instead of Qt being a library you can plug up to your own code so you can throw on a GUI, you must immerse your app completely and utterly, typically by developing with the Qt library from the very start. This means there are many clear boundaries in your code where, for example, Qt and stdlib meet (say converting an std::vector from another library into a QList).\nMoreover, I find imperative GUI libraries, such as Qt, quite unsatisfying in terms of expressiveness, readability, and cleanliness. There\u0026rsquo;s no clear flow of data through your GUI, as if you were to map out all the callbacks and subsequent state mutations, it would practically be spaghetti. This is in contrast to something like React where the data flow is strongly driven in a single direction. Here also lies a major architectural issue: There is no single source of truth. This occurs even at the smallest of scales, for example when syncing a label\u0026rsquo;s text with your data.\nStyling and other visual parts of Qt also leave a lot to be desired. I\u0026rsquo;m shocked that Qt does not default to GPU accelerated widget rendering when available. Screen resolutions are increasing and CPU rasterization simply cannot keep up.\nOverall however, it gets the job done. It manages to stay relatively low (compared to Electron) on memory consumption while offering a broad range of utilities and features. There is still much room for improvement though.\n   WPF (and other Microsoft UI)  WPF and its ilk are a great follow up to Qt, as they solve the problem of lacking a single source of truth and integrate seamlessly with the rest of C#.\nXAML offers property binding which is an acceptable way to solve the problem of synchronising two stores of data. By simply binding to a variable when setting the property of a widget, you can trivially bind two different datum and never have to worry about it again. On the other hand, having to manage the gap between C# and XAML is still an issue. Things start to get messy when trying to mutate the widget tree on the C# side, and vice versa. Amongst the community there seems to be a majority consensus of using MVC (or some other framework such as ReactiveUI) to architect your application around. Beyond my personal disgust for MVC (see why here), it feels rather restricting that you\u0026rsquo;re expected to lock yourself into a very specific design.\nFinally, of course, there is the problem that it is exclusive to Windows. There is Avalonia, which is a step in the right direction, but it is still too young to see major adoption and support. Another point of concern is that Microsoft seems rather unstable and trigger-happy in terms of their UI story.\n   Flutter  Flutter began as a mobile UI library and it is very good at that. Meanwhile, the desktop port seems unfinished, neglected, and mostly just appears to be an afterthought.\nIt is very clear that Flutter is highly focused on mobile platforms given the oversized widgets, sliver headers, bottom swipeable tabs, flick to scroll, hero animations, and other widget features you would never find in a desktop-focused GUI. This is quite unfortunate since the Flutter architecture itself is terrific thanks to an attractive declarative API backed by an accessible retained element tree.\nThis by all means can be fixed by building a separate widget library designed specifically for the desktop from the ground up. Somehow though, I doubt this is a venture Google would want to fund. It\u0026rsquo;s a shame since Flutter\u0026rsquo;s architecture shows so much promise in terms of ease of access, productivity, and escape hatches.\n   Immediate-mode  Dear ImGui (and other immediate-mode UI) present a very elegant solution to many of the problems I\u0026rsquo;ve mentioned. For one, you don\u0026rsquo;t need to bother with MVC or any kind of binding or callbacks since the very notion of immediate-mode UI revolves around storing and pulling to/from a common data source. Moreover, Dear ImGui doesn\u0026rsquo;t ask for a large widget interface to implemented or for custom data structures; you can reuse your existing data structure to describe a UI. It is very much plug-and-play in that regard and feels like an integratable library rather than a bloated framework.\nEven issues that some cite as being downsides of Dear ImGui are fixable. You don\u0026rsquo;t have to render at 60 fps - only render when you receive an event. You don\u0026rsquo;t have to regenerate the entire tree every frame - perform some diffing to reuse and recycle computation. Most of these supposed issues boil down to the implementation, not with the architecture itself.\nWith that said, there are still some fundamental downsides with being fully immediate-mode. One such downside is layout. Since everything is computed in one go, you can\u0026rsquo;t backtrack to fix up layout after receiving new information (e.g., sizing to fill but later discovering more room to fill; too bad, you can\u0026rsquo;t go back). At this point, you\u0026rsquo;ll have to resort to storing an intermediate tree to do a separate layout pass.\nIf you\u0026rsquo;re willing to give up some of the purity of full immediate-mode and begin to introduce intermediate trees and layout callbacks then you could very well fix these issues. Though, I also find there is a mentality in immediate-mode UI that it should only be used for internal tooling (mostly for game engines). I whole-heartedly disagree. If you choose to make it more robust with intermediate trees and whatnot, then you have a React-esque library on your hands which is more than capable for more complex desktop applications, only missing a desktop focused widget library (as opposed to tooling focused).\n   Closing thoughts  There are many GUI libraries I left out, so I\u0026rsquo;ll briefly explain why:\n FLTK, Tk, libui, Lazarus, etc: They are not as robust as one would wish for more complex applications. They do not offer many escape hatches as they are really an abstraction of the OS GUI (which also do not offer many escape hatches). As a result, things such as custom widgets and styling are greatly lacking. JavaFX, Swing, GTK, etc: These generally fall in the same camp as Qt and WPF.  GUI is an incredibly difficult problem and an incredibly ugly problem. There is no elegance to be found here. A good GUI API implementation is one that is willing to be ugly for the sake of performance, accessibility, and usability.\n","date":"Jul 31","permalink":"/post/gui/","tags":null,"title":"The grim GUI landscape"},{"categories":null,"contents":"","date":"Nov 26","permalink":"/articles/","tags":null,"title":"Articles"}]